from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Any
import json

import numpy as np
import pandas as pd
import timm
import torch
from safetensors.torch import load_file
from PIL import Image
from timm.data import create_transform, resolve_data_config
from torch import Tensor, nn
from torch.nn import functional as F

# ======================== æ ¸å¿ƒé…ç½®åŒº ========================
# 1. æ¨¡å‹ç›¸å…³ï¼ˆç›¸å¯¹è·¯å¾„ï¼Œé€‚é…ä½ çš„ç›®å½•ç»“æ„ï¼‰
MODEL_DIR_REL = "./models--SmilingWolf--wd-eva02-large-tagger-v3"  # æ¨¡å‹æ–‡ä»¶å¤¹ç›¸å¯¹è·¯å¾„

# 2. å›¾ç‰‡ä¸è¾“å‡ºé…ç½®
IMAGE_DIR_REL = r"image_tagger\sample_image"  # å¾…å¤„ç†å›¾ç‰‡æ–‡ä»¶å¤¹
OUTPUT_DIR_REL = r"image_tagger\tags_output"  # JSONè¾“å‡ºæ–‡ä»¶å¤¹
GEN_THRESHOLD = 0.35  # é€šç”¨æ ‡ç­¾é˜ˆå€¼
CHAR_THRESHOLD = 0.75  # è§’è‰²æ ‡ç­¾é˜ˆå€¼
SUPPORTED_IMG_EXT = ["jpg", "jpeg", "png", "webp", "bmp"]  # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
# ===========================================================================

# è®¾å¤‡é…ç½®ï¼ˆè‡ªåŠ¨æ£€æµ‹GPU/CPUï¼‰
torch_device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def pil_ensure_rgb(image: Image.Image) -> Image.Image:
    """ç¡®ä¿å›¾ç‰‡ä¸ºRGBæ ¼å¼ï¼Œå¤„ç†é€æ˜é€šé“/è°ƒè‰²æ¿"""
    if image.mode not in ["RGB", "RGBA"]:
        image = image.convert("RGBA") if "transparency" in image.info else image.convert("RGB")
    if image.mode == "RGBA":
        canvas = Image.new("RGBA", image.size, (255, 255, 255))
        canvas.alpha_composite(image)
        image = canvas.convert("RGB")
    return image


def pil_pad_square(image: Image.Image) -> Image.Image:
    """å°†å›¾ç‰‡å¡«å……ä¸ºæ­£æ–¹å½¢ï¼ˆç™½è‰²èƒŒæ™¯ï¼‰"""
    w, h = image.size
    px = max(image.size)
    canvas = Image.new("RGB", (px, px), (255, 255, 255))
    canvas.paste(image, ((px - w) // 2, (px - h) // 2))
    return canvas


@dataclass
class LabelData:
    """æ ‡ç­¾æ•°æ®ç»“æ„"""
    names: list[str]
    rating: list[np.int64]
    general: list[np.int64]
    character: list[np.int64]
    num_labels: int  # æ–°å¢ï¼šæ ‡ç­¾æ€»æ•°


def load_labels_local() -> LabelData:
    """ä»æœ¬åœ°æ¨¡å‹ç›®å½•é€’å½’æŸ¥æ‰¾å¹¶åŠ è½½selected_tags.csv"""
    model_dir = Path(MODEL_DIR_REL).resolve()
    csv_paths = list(model_dir.rglob("selected_tags.csv"))

    if not csv_paths:
        raise FileNotFoundError(
            f"æœªæ‰¾åˆ°æ ‡ç­¾æ–‡ä»¶ï¼è¯·æ£€æŸ¥ {model_dir} åŠå…¶å­ç›®å½•ä¸‹æ˜¯å¦æœ‰selected_tags.csv"
        )

    df = pd.read_csv(csv_paths[0], usecols=["name", "category"])
    return LabelData(
        names=df["name"].tolist(),
        rating=list(np.where(df["category"] == 9)[0]),
        general=list(np.where(df["category"] == 0)[0]),
        character=list(np.where(df["category"] == 4)[0]),
        num_labels=len(df)  # è·å–å®é™…æ ‡ç­¾æ•°é‡
    )


def load_model_local(num_labels: int) -> nn.Module:
    """ä»æœ¬åœ°åŠ è½½eva02æ¨¡å‹ï¼ˆé€‚é…å®é™…æ ‡ç­¾ç»´åº¦ï¼Œä»…ç”¨æœ¬åœ°æ–‡ä»¶ï¼Œä¸ä¸‹è½½ï¼‰"""
    model_dir = Path(MODEL_DIR_REL).resolve()
    if not model_dir.is_dir():
        raise FileNotFoundError(f"æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_dir}")

    # 1. æŸ¥æ‰¾é…ç½®æ–‡ä»¶å’Œæƒé‡æ–‡ä»¶
    config_paths = list(model_dir.rglob("config.json"))
    weight_paths = {
        "safetensors": list(model_dir.rglob("*.safetensors")),
        "msgpack": list(model_dir.rglob("*.msgpack")),
        "bin": list(model_dir.rglob("*.bin")),
        "pth": list(model_dir.rglob("*.pth")),
    }

    # æ ¡éªŒå¿…è¦æ–‡ä»¶
    if not config_paths:
        raise FileNotFoundError(f"åœ¨{model_dir}æœªæ‰¾åˆ°config.json")
    if not any(weight_paths.values()):
        raise FileNotFoundError(f"åœ¨{model_dir}æœªæ‰¾åˆ°æ¨¡å‹æƒé‡æ–‡ä»¶ï¼ˆ.safetensors/.msgpack/.bin/.pthï¼‰")

    # 2. ä¼˜å…ˆåŠ è½½safetensorsï¼ˆä½ çš„ç›®å½•é‡Œæœ‰è¯¥æ–‡ä»¶ï¼‰
    if weight_paths["safetensors"]:
        weight_path = weight_paths["safetensors"][0]
        state_dict = load_file(weight_path)
    else:
        weight_path = weight_paths["msgpack"][0] if weight_paths["msgpack"] else weight_paths["bin"][0]
        state_dict = torch.load(weight_path, map_location="cpu")

    # 3. åˆ›å»ºé€‚é…å®é™…æ ‡ç­¾æ•°é‡çš„EVA02æ¨¡å‹
    model = timm.create_model(
        "eva02_large_patch14_448",
        pretrained=False,
        num_classes=num_labels  # å…³é”®ä¿®å¤ï¼šä½¿ç”¨å®é™…æ ‡ç­¾æ•°é‡ï¼Œè€Œéå›ºå®š14112
    ).eval()

    # é€‚é…æƒé‡æ ¼å¼ï¼ˆå¤„ç†å¯èƒ½çš„state_dictåµŒå¥—ï¼‰
    if "state_dict" in state_dict:
        state_dict = state_dict["state_dict"]

    # å…³é”®ä¿®å¤ï¼šè¿‡æ»¤æ‰ä¸åŒ¹é…çš„å±‚ï¼ˆä»…ä¿ç•™èƒ½åŠ è½½çš„æƒé‡ï¼‰
    model_state_dict = model.state_dict()
    filtered_state_dict = {}
    for k, v in state_dict.items():
        if k in model_state_dict and v.shape == model_state_dict[k].shape:
            filtered_state_dict[k] = v
        else:
            print(f"âš ï¸ è·³è¿‡ä¸åŒ¹é…çš„æƒé‡: {k} (checkpoint shape: {v.shape}, model shape: {model_state_dict.get(k, 'ä¸å­˜åœ¨').shape})")

    # åŠ è½½è¿‡æ»¤åçš„æƒé‡
    model.load_state_dict(filtered_state_dict, strict=False)

    # ç§»åˆ°æŒ‡å®šè®¾å¤‡
    model = model.to(torch_device)
    return model


def get_tags(probs: Tensor, labels: LabelData) -> Dict[str, Any]:
    """è§£ææ¨¡å‹è¾“å‡ºä¸ºæ ‡ç­¾ç»“æœï¼Œè¿”å›JSONå¯åºåˆ—åŒ–çš„å­—å…¸"""
    probs_np = probs.cpu().numpy()

    # è¯„åˆ†æ ‡ç­¾ï¼ˆsafe/sensitiveç­‰ï¼‰
    rating_labels = {labels.names[i]: float(probs_np[i]) for i in labels.rating if i < len(probs_np)}

    # é€šç”¨æ ‡ç­¾ï¼ˆé˜ˆå€¼è¿‡æ»¤+æ’åºï¼‰
    gen_labels = {
        labels.names[i]: float(probs_np[i])
        for i in labels.general
        if i < len(probs_np) and probs_np[i] > GEN_THRESHOLD
    }
    gen_labels = dict(sorted(gen_labels.items(), key=lambda x: x[1], reverse=True))

    # è§’è‰²æ ‡ç­¾ï¼ˆé˜ˆå€¼è¿‡æ»¤+æ’åºï¼‰
    char_labels = {
        labels.names[i]: float(probs_np[i])
        for i in labels.character
        if i < len(probs_np) and probs_np[i] > CHAR_THRESHOLD
    }
    char_labels = dict(sorted(char_labels.items(), key=lambda x: x[1], reverse=True))

    # ç”Ÿæˆcaptionå’Œæ ¼å¼åŒ–æ ‡ç­¾
    combined_names = list(gen_labels.keys()) + list(char_labels.keys())
    caption = ", ".join(combined_names)
    taglist = caption.replace("_", " ").replace("(", "\(").replace(")", "\)")

    return {
        "caption": caption,
        "taglist": taglist,
        "ratings": rating_labels,
        "character_tags": char_labels,
        "general_tags": gen_labels,
        "gen_threshold": GEN_THRESHOLD,
        "char_threshold": CHAR_THRESHOLD
    }


def process_single_image(img_path: Path, model: nn.Module, transform, labels: LabelData):
    """å¤„ç†å•å¼ å›¾ç‰‡ï¼Œç”ŸæˆåŒåJSONæ ‡æ³¨æ–‡ä»¶"""
    try:
        # åŠ è½½å¹¶é¢„å¤„ç†å›¾ç‰‡
        img = Image.open(img_path)
        img = pil_ensure_rgb(img)
        img = pil_pad_square(img)
        inputs = transform(img).unsqueeze(0).to(torch_device)
        inputs = inputs[:, [2, 1, 0]]  # RGBè½¬BGR

        # æ¨¡å‹æ¨ç†
        with torch.inference_mode():
            outputs = model(inputs)
            outputs = F.sigmoid(outputs).squeeze(0)

        # è§£ææ ‡ç­¾
        tag_result = get_tags(outputs, labels)

        # ç”Ÿæˆè¾“å‡ºè·¯å¾„ï¼ˆåŒåJSONï¼‰
        output_dir = Path(OUTPUT_DIR_REL).resolve()
        output_dir.mkdir(parents=True, exist_ok=True)
        json_path = output_dir / f"{img_path.stem}.json"

        # ä¿å­˜JSONæ–‡ä»¶
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(tag_result, f, ensure_ascii=False, indent=4)

        return True, img_path.name, json_path.name

    except Exception as e:
        return False, img_path.name, str(e)


def main():
    """ä¸»å‡½æ•°ï¼šä¸€é”®è¿è¡Œæ‰€æœ‰é€»è¾‘"""
    # 1. æ ¡éªŒç›®å½•
    image_dir = Path(IMAGE_DIR_REL).resolve()
    if not image_dir.is_dir():
        raise FileNotFoundError(f"å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {image_dir}")

    # 2. å…ˆåŠ è½½æ ‡ç­¾ï¼ˆè·å–å®é™…æ ‡ç­¾æ•°é‡ï¼‰ï¼Œå†åŠ è½½æ¨¡å‹
    print("ğŸ” åŠ è½½æœ¬åœ°æ ‡ç­¾æ–‡ä»¶...")
    labels = load_labels_local()
    print(f"ğŸ“Œ æ£€æµ‹åˆ°æ ‡ç­¾æ•°é‡: {labels.num_labels}")

    print("ğŸ” åŠ è½½æœ¬åœ°æ¨¡å‹ï¼ˆé€‚é…æ ‡ç­¾ç»´åº¦ï¼‰...")
    model = load_model_local(labels.num_labels)

    # 3. åˆ›å»ºå›¾ç‰‡é¢„å¤„ç†è§„åˆ™
    transform = create_transform(**resolve_data_config(model.pretrained_cfg, model=model))

    # 4. ç²¾å‡†æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡ï¼ˆå»é‡+è¿‡æ»¤éšè—æ–‡ä»¶ï¼‰
    image_files = []
    # ç»Ÿä¸€è½¬ä¸ºå°å†™æ‰©å±•åï¼Œé¿å…é‡å¤
    ext_set = set([ext.lower() for ext in SUPPORTED_IMG_EXT])

    for file in image_dir.iterdir():
        # è·³è¿‡ç›®å½•å’Œéšè—æ–‡ä»¶
        if file.is_dir() or file.name.startswith("."):
            continue
        # è·å–æ–‡ä»¶æ‰©å±•åï¼ˆå°å†™ï¼‰
        file_ext = file.suffix.lstrip(".").lower()
        if file_ext in ext_set:
            image_files.append(file)

    # å»é‡ï¼ˆé¿å…å¤§å°å†™æ‰©å±•åé‡å¤ï¼‰
    image_files = list(dict.fromkeys(image_files))

    # æ‰“å°è¯¦ç»†çš„å›¾ç‰‡åˆ—è¡¨
    print(f"\nğŸ“‚ æ‰«æåˆ°å›¾ç‰‡ç›®å½•: {image_dir}")
    print(f"ğŸ“‹ æ”¯æŒçš„æ ¼å¼: {', '.join(SUPPORTED_IMG_EXT)}")
    print(f"ğŸ”¢ æ£€æµ‹åˆ°æœ‰æ•ˆå›¾ç‰‡æ•°é‡: {len(image_files)}")

    if len(image_files) > 0:
        print("ğŸ“ å›¾ç‰‡åˆ—è¡¨:")
        for idx, img_file in enumerate(image_files, 1):
            print(f"   {idx}. {img_file.name}")
    else:
        print(f"âš ï¸ åœ¨ {image_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½•æ”¯æŒçš„å›¾ç‰‡æ–‡ä»¶")
        return

    # 5. æ‰¹é‡å¤„ç†å›¾ç‰‡ï¼ˆç²¾å‡†ç»Ÿè®¡ï¼‰
    print(f"\nğŸš€ å¼€å§‹å¤„ç† {len(image_files)} å¼ å›¾ç‰‡...")
    success_count = 0
    fail_list = []

    for idx, img_file in enumerate(image_files, 1):
        success, img_name, msg = process_single_image(img_file, model, transform, labels)
        if success:
            success_count += 1
            print(f"[{idx}/{len(image_files)}] âœ… å¤„ç†å®Œæˆ: {img_name} -> {msg}")
        else:
            fail_list.append((img_name, msg))
            print(f"[{idx}/{len(image_files)}] âŒ å¤„ç†å¤±è´¥: {img_name} - {msg}")

    # 6. è¾“å‡ºç²¾å‡†çš„ç»Ÿè®¡ç»“æœ
    print(f"\nğŸ“Š å¤„ç†ç»“æœç»Ÿè®¡:")
    print(f"   æ€»è®¡æ‰«æåˆ°: {len(image_files)} å¼ ")
    print(f"   æˆåŠŸå¤„ç†: {success_count} å¼ ")
    print(f"   å¤„ç†å¤±è´¥: {len(fail_list)} å¼ ")

    if fail_list:
        print(f"\nâŒ å¤±è´¥è¯¦æƒ…:")
        for img_name, err_msg in fail_list:
            print(f"   {img_name}: {err_msg[:100]}...")  # æˆªæ–­è¿‡é•¿çš„é”™è¯¯ä¿¡æ¯

    print(f"\nğŸ“ æ ‡æ³¨æ–‡ä»¶ä¿å­˜è·¯å¾„: {Path(OUTPUT_DIR_REL).resolve()}")


if __name__ == "__main__":
    # ä¸€é”®è¿è¡Œï¼Œæ— å‘½ä»¤è¡Œå‚æ•°
    main()